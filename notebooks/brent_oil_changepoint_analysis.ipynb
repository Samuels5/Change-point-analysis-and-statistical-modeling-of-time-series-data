{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5cf3747",
   "metadata": {},
   "source": [
    "# Change Point Analysis and Statistical Modeling of Brent Oil Prices\n",
    "\n",
    "## Business Objective\n",
    "This analysis studies how important geopolitical and economic events affect Brent oil prices using Bayesian change point detection. We aim to:\n",
    "- Identify statistically significant structural breaks in oil price behavior\n",
    "- Associate detected change points with major events\n",
    "- Quantify the impact of events on price dynamics\n",
    "- Provide actionable insights for investors, analysts, and policymakers\n",
    "\n",
    "## Data Overview\n",
    "- **Brent Oil Prices**: Daily prices from May 20, 1987 to September 30, 2022\n",
    "- **Key Events**: 15 major geopolitical, economic, and OPEC policy events that potentially impacted oil markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b38b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Statistical and time series libraries\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Bayesian change point detection\n",
    "import pymc3 as pm\n",
    "import theano.tensor as tt\n",
    "import arviz as az\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyMC3 version: {pm.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9907c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Explore the Datasets\n",
    "\n",
    "# Load Brent oil price data\n",
    "oil_data = pd.read_csv('../data/brent_oil_prices.csv')\n",
    "print(\"Brent Oil Price Data:\")\n",
    "print(f\"Shape: {oil_data.shape}\")\n",
    "print(f\"Date range: {oil_data['Date'].iloc[0]} to {oil_data['Date'].iloc[-1]}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(oil_data.head())\n",
    "print(\"\\nData types:\")\n",
    "print(oil_data.dtypes)\n",
    "print(f\"\\nPrice statistics:\")\n",
    "print(oil_data['Price'].describe())\n",
    "\n",
    "# Load key events data\n",
    "events_data = pd.read_csv('../data/key_events.csv')\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Key Events Data:\")\n",
    "print(f\"Shape: {events_data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(events_data.head())\n",
    "print(\"\\nEvent categories:\")\n",
    "print(events_data['Category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c0ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing and Cleaning\n",
    "\n",
    "# Convert date columns to datetime\n",
    "oil_data['Date'] = pd.to_datetime(oil_data['Date'], format='%d-%b-%y')\n",
    "events_data['Date'] = pd.to_datetime(events_data['Date'])\n",
    "\n",
    "# Sort by date\n",
    "oil_data = oil_data.sort_values('Date').reset_index(drop=True)\n",
    "events_data = events_data.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values in oil data:\")\n",
    "print(oil_data.isnull().sum())\n",
    "print(\"\\nMissing values in events data:\")\n",
    "print(events_data.isnull().sum())\n",
    "\n",
    "# Create log returns for better modeling\n",
    "oil_data['Log_Price'] = np.log(oil_data['Price'])\n",
    "oil_data['Log_Returns'] = oil_data['Log_Price'].diff()\n",
    "\n",
    "# Remove first row with NaN return\n",
    "oil_data = oil_data.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nProcessed oil data shape: {oil_data.shape}\")\n",
    "print(f\"Date range: {oil_data['Date'].min()} to {oil_data['Date'].max()}\")\n",
    "print(f\"\\nLog returns statistics:\")\n",
    "print(oil_data['Log_Returns'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b827e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "# Plot oil price time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "\n",
    "# Raw prices\n",
    "axes[0].plot(oil_data['Date'], oil_data['Price'], linewidth=0.8, color='darkblue')\n",
    "axes[0].set_title('Brent Oil Prices (1987-2022)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price (USD/barrel)')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Log prices\n",
    "axes[1].plot(oil_data['Date'], oil_data['Log_Price'], linewidth=0.8, color='darkgreen')\n",
    "axes[1].set_title('Log Brent Oil Prices', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Log Price')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Log returns\n",
    "axes[2].plot(oil_data['Date'], oil_data['Log_Returns'], linewidth=0.5, color='red', alpha=0.7)\n",
    "axes[2].set_title('Daily Log Returns', fontsize=14, fontweight='bold')\n",
    "axes[2].set_ylabel('Log Returns')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Add event markers\n",
    "for _, event in events_data.iterrows():\n",
    "    event_date = event['Date']\n",
    "    if event_date >= oil_data['Date'].min() and event_date <= oil_data['Date'].max():\n",
    "        for ax in axes:\n",
    "            ax.axvline(x=event_date, color='red', linestyle='--', alpha=0.6, linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Event analysis\n",
    "print(\"Key Events Timeline:\")\n",
    "for _, event in events_data.iterrows():\n",
    "    print(f\"{event['Date'].strftime('%Y-%m-%d')}: {event['Event']} ({event['Category']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7932980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series Properties Analysis\n",
    "\n",
    "# Test for stationarity\n",
    "def check_stationarity(timeseries, title):\n",
    "    print(f'\\n{title}')\n",
    "    print('-' * 50)\n",
    "    \n",
    "    # Perform Augmented Dickey-Fuller test\n",
    "    result = adfuller(timeseries.dropna())\n",
    "    print(f'ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'\\t{key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Series is stationary\")\n",
    "    else:\n",
    "        print(\"Series is non-stationary\")\n",
    "\n",
    "# Check stationarity of different series\n",
    "check_stationarity(oil_data['Price'], 'Raw Prices Stationarity Test')\n",
    "check_stationarity(oil_data['Log_Price'], 'Log Prices Stationarity Test')\n",
    "check_stationarity(oil_data['Log_Returns'], 'Log Returns Stationarity Test')\n",
    "\n",
    "# Volatility clustering analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Log returns distribution\n",
    "axes[0,0].hist(oil_data['Log_Returns'], bins=100, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Distribution of Log Returns')\n",
    "axes[0,0].set_xlabel('Log Returns')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Q-Q plot for normality check\n",
    "from scipy.stats import probplot\n",
    "probplot(oil_data['Log_Returns'].dropna(), dist=\"norm\", plot=axes[0,1])\n",
    "axes[0,1].set_title('Q-Q Plot: Log Returns vs Normal Distribution')\n",
    "\n",
    "# Rolling volatility (30-day window)\n",
    "oil_data['Rolling_Vol'] = oil_data['Log_Returns'].rolling(window=30).std()\n",
    "axes[1,0].plot(oil_data['Date'], oil_data['Rolling_Vol'], linewidth=0.8, color='purple')\n",
    "axes[1,0].set_title('30-Day Rolling Volatility')\n",
    "axes[1,0].set_xlabel('Date')\n",
    "axes[1,0].set_ylabel('Volatility')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Autocorrelation of squared returns (volatility clustering)\n",
    "from statsmodels.tsa.stattools import acf\n",
    "squared_returns = oil_data['Log_Returns'] ** 2\n",
    "lags = range(1, 51)\n",
    "autocorr = [acf(squared_returns.dropna(), nlags=lag, fft=False)[-1] for lag in lags]\n",
    "axes[1,1].plot(lags, autocorr, 'o-', markersize=4)\n",
    "axes[1,1].set_title('Autocorrelation of Squared Returns')\n",
    "axes[1,1].set_xlabel('Lag')\n",
    "axes[1,1].set_ylabel('Autocorrelation')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c054917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian Change Point Detection Model\n",
    "\n",
    "# Prepare data for modeling - use log returns for better statistical properties\n",
    "returns = oil_data['Log_Returns'].dropna().values\n",
    "n_observations = len(returns)\n",
    "print(f\"Modeling {n_observations} daily log returns\")\n",
    "\n",
    "# Simple single change point model\n",
    "with pm.Model() as change_point_model:\n",
    "    # Prior for the change point location (uniform over all possible days)\n",
    "    tau = pm.DiscreteUniform('tau', lower=0, upper=n_observations-1)\n",
    "    \n",
    "    # Priors for the parameters before and after the change point\n",
    "    # Mean returns before and after change point\n",
    "    mu_1 = pm.Normal('mu_1', mu=0, sigma=0.01)  # Before change point\n",
    "    mu_2 = pm.Normal('mu_2', mu=0, sigma=0.01)  # After change point\n",
    "    \n",
    "    # Standard deviations before and after change point\n",
    "    sigma_1 = pm.HalfNormal('sigma_1', sigma=0.05)\n",
    "    sigma_2 = pm.HalfNormal('sigma_2', sigma=0.05)\n",
    "    \n",
    "    # Switch function to select parameters based on change point\n",
    "    mu = pm.math.switch(tau >= np.arange(n_observations), mu_1, mu_2)\n",
    "    sigma = pm.math.switch(tau >= np.arange(n_observations), sigma_1, sigma_2)\n",
    "    \n",
    "    # Likelihood\n",
    "    observations = pm.Normal('obs', mu=mu, sigma=sigma, observed=returns)\n",
    "\n",
    "print(\"Model specification complete. Starting MCMC sampling...\")\n",
    "\n",
    "# Sample from the posterior\n",
    "with change_point_model:\n",
    "    trace = pm.sample(2000, tune=1000, chains=2, cores=1, progressbar=True)\n",
    "    \n",
    "print(\"MCMC sampling complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18cd47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Diagnostics and Results\n",
    "\n",
    "# Check model convergence\n",
    "print(\"Model Convergence Diagnostics:\")\n",
    "print(\"=\"*50)\n",
    "summary = az.summary(trace)\n",
    "print(summary)\n",
    "\n",
    "# Plot trace plots for key parameters\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Trace plots\n",
    "az.plot_trace(trace, var_names=['tau'], axes=axes[0,:])\n",
    "az.plot_trace(trace, var_names=['mu_1', 'mu_2'], axes=axes[1,:])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract change point information\n",
    "tau_samples = trace['tau']\n",
    "tau_mean = int(np.mean(tau_samples))\n",
    "tau_median = int(np.median(tau_samples))\n",
    "\n",
    "# Convert index back to date\n",
    "change_point_date = oil_data['Date'].iloc[tau_mean + 1]  # +1 because we dropped first row\n",
    "\n",
    "print(f\"\\nChange Point Analysis Results:\")\n",
    "print(f\"Most probable change point (mean): Day {tau_mean}\")\n",
    "print(f\"Change point date: {change_point_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Median change point: Day {tau_median}\")\n",
    "\n",
    "# Plot change point posterior distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(tau_samples, bins=100, alpha=0.7, density=True, color='skyblue', edgecolor='black')\n",
    "plt.axvline(tau_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {tau_mean}')\n",
    "plt.axvline(tau_median, color='orange', linestyle='--', linewidth=2, label=f'Median: {tau_median}')\n",
    "plt.xlabel('Change Point Index')\n",
    "plt.ylabel('Posterior Density')\n",
    "plt.title('Posterior Distribution of Change Point Location')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event Association and Impact Quantification\n",
    "\n",
    "# Find events closest to the detected change point\n",
    "def find_closest_events(change_point_date, events_df, window_days=30):\n",
    "    \"\"\"Find events within a specified window of the change point\"\"\"\n",
    "    closest_events = []\n",
    "    \n",
    "    for _, event in events_df.iterrows():\n",
    "        days_diff = abs((event['Date'] - change_point_date).days)\n",
    "        if days_diff <= window_days:\n",
    "            closest_events.append({\n",
    "                'Event': event['Event'],\n",
    "                'Date': event['Date'],\n",
    "                'Category': event['Category'],\n",
    "                'Days_from_CP': (event['Date'] - change_point_date).days,\n",
    "                'Description': event['Description']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(closest_events).sort_values('Days_from_CP', key=abs)\n",
    "\n",
    "# Find events near the main change point\n",
    "closest_events = find_closest_events(change_point_date, events_data, window_days=60)\n",
    "\n",
    "print(\"Events closest to detected change point:\")\n",
    "print(\"=\"*60)\n",
    "if len(closest_events) > 0:\n",
    "    for _, event in closest_events.iterrows():\n",
    "        direction = \"after\" if event['Days_from_CP'] > 0 else \"before\"\n",
    "        print(f\"{event['Date'].strftime('%Y-%m-%d')}: {event['Event']}\")\n",
    "        print(f\"  Category: {event['Category']}\")\n",
    "        print(f\"  {abs(event['Days_from_CP'])} days {direction} change point\")\n",
    "        print(f\"  Description: {event['Description']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No events found within 60 days of the change point\")\n",
    "\n",
    "# Quantify impact - compare parameters before and after change point\n",
    "mu_1_samples = trace['mu_1']\n",
    "mu_2_samples = trace['mu_2']\n",
    "sigma_1_samples = trace['sigma_1']\n",
    "sigma_2_samples = trace['sigma_2']\n",
    "\n",
    "print(\"Parameter Changes at Change Point:\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Mean return before CP: {np.mean(mu_1_samples):.6f} ± {np.std(mu_1_samples):.6f}\")\n",
    "print(f\"Mean return after CP:  {np.mean(mu_2_samples):.6f} ± {np.std(mu_2_samples):.6f}\")\n",
    "print(f\"Volatility before CP:  {np.mean(sigma_1_samples):.6f} ± {np.std(sigma_1_samples):.6f}\")\n",
    "print(f\"Volatility after CP:   {np.mean(sigma_2_samples):.6f} ± {np.std(sigma_2_samples):.6f}\")\n",
    "\n",
    "# Calculate probability of parameter changes\n",
    "mu_diff = mu_2_samples - mu_1_samples\n",
    "sigma_diff = sigma_2_samples - sigma_1_samples\n",
    "\n",
    "prob_mu_increase = np.mean(mu_diff > 0)\n",
    "prob_sigma_increase = np.mean(sigma_diff > 0)\n",
    "\n",
    "print(f\"\\nProbability of mean return increase: {prob_mu_increase:.2%}\")\n",
    "print(f\"Probability of volatility increase: {prob_sigma_increase:.2%}\")\n",
    "\n",
    "# Convert to annualized percentage changes\n",
    "annual_mu_1 = np.mean(mu_1_samples) * 252 * 100  # 252 trading days\n",
    "annual_mu_2 = np.mean(mu_2_samples) * 252 * 100\n",
    "annual_sigma_1 = np.mean(sigma_1_samples) * np.sqrt(252) * 100\n",
    "annual_sigma_2 = np.mean(sigma_2_samples) * np.sqrt(252) * 100\n",
    "\n",
    "print(f\"\\nAnnualized Impact:\")\n",
    "print(f\"Expected return changed from {annual_mu_1:.2f}% to {annual_mu_2:.2f}%\")\n",
    "print(f\"Volatility changed from {annual_sigma_1:.2f}% to {annual_sigma_2:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Results Visualization\n",
    "\n",
    "# Create a comprehensive dashboard-style visualization\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "\n",
    "# Create a grid layout\n",
    "gs = fig.add_gridspec(4, 3, height_ratios=[1, 1, 1, 0.8], hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Price time series with change point and events\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(oil_data['Date'], oil_data['Price'], linewidth=1, color='darkblue', alpha=0.8)\n",
    "ax1.axvline(x=change_point_date, color='red', linestyle='-', linewidth=3, label=f'Detected Change Point: {change_point_date.strftime(\"%Y-%m-%d\")}')\n",
    "\n",
    "# Add event markers with different colors for categories\n",
    "colors = {'Geopolitical': 'orange', 'Economic': 'green', 'OPEC Policy': 'purple', 'Economic Sanctions': 'brown', 'Policy': 'pink'}\n",
    "for _, event in events_data.iterrows():\n",
    "    if event['Date'] >= oil_data['Date'].min() and event['Date'] <= oil_data['Date'].max():\n",
    "        color = colors.get(event['Category'], 'gray')\n",
    "        ax1.axvline(x=event['Date'], color=color, linestyle='--', alpha=0.7, linewidth=1)\n",
    "\n",
    "ax1.set_title('Brent Oil Prices with Detected Change Point and Key Events', fontsize=16, fontweight='bold')\n",
    "ax1.set_ylabel('Price (USD/barrel)')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# 2. Log returns with regime identification\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "ax2.plot(oil_data['Date'], oil_data['Log_Returns'], linewidth=0.5, color='red', alpha=0.6)\n",
    "ax2.axvline(x=change_point_date, color='red', linestyle='-', linewidth=3)\n",
    "ax2.axhline(y=np.mean(mu_1_samples), color='blue', linestyle='--', alpha=0.8, label=f'Regime 1 Mean: {np.mean(mu_1_samples):.4f}')\n",
    "ax2.axhline(y=np.mean(mu_2_samples), color='green', linestyle='--', alpha=0.8, label=f'Regime 2 Mean: {np.mean(mu_2_samples):.4f}')\n",
    "ax2.set_title('Daily Log Returns with Regime Means', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Log Returns')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Parameter posterior distributions\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "ax3.hist(mu_1_samples, bins=50, alpha=0.7, color='blue', label='Before CP', density=True)\n",
    "ax3.hist(mu_2_samples, bins=50, alpha=0.7, color='green', label='After CP', density=True)\n",
    "ax3.set_title('Mean Return Distributions')\n",
    "ax3.set_xlabel('Mean Return')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "ax4.hist(sigma_1_samples, bins=50, alpha=0.7, color='blue', label='Before CP', density=True)\n",
    "ax4.hist(sigma_2_samples, bins=50, alpha=0.7, color='green', label='After CP', density=True)\n",
    "ax4.set_title('Volatility Distributions')\n",
    "ax4.set_xlabel('Volatility')\n",
    "ax4.set_ylabel('Density')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Change point uncertainty\n",
    "ax5 = fig.add_subplot(gs[2, 2])\n",
    "ax5.hist(tau_samples, bins=100, alpha=0.7, color='orange', density=True)\n",
    "ax5.axvline(tau_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {tau_mean}')\n",
    "ax5.set_title('Change Point Uncertainty')\n",
    "ax5.set_xlabel('Time Index')\n",
    "ax5.set_ylabel('Density')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Event timeline\n",
    "ax6 = fig.add_subplot(gs[3, :])\n",
    "y_positions = []\n",
    "for i, (_, event) in enumerate(events_data.iterrows()):\n",
    "    y_pos = hash(event['Category']) % 5\n",
    "    y_positions.append(y_pos)\n",
    "    color = colors.get(event['Category'], 'gray')\n",
    "    ax6.scatter(event['Date'], y_pos, color=color, s=100, alpha=0.8)\n",
    "    \n",
    "    # Add event labels for major events\n",
    "    if event['Event'] in ['Gulf War Invasion', 'September 11 Attacks', 'Lehman Brothers Collapse', 'WHO Declares Pandemic', 'Russia Ukraine War']:\n",
    "        ax6.annotate(event['Event'], (event['Date'], y_pos), xytext=(10, 10), \n",
    "                    textcoords='offset points', fontsize=8, rotation=45)\n",
    "\n",
    "ax6.axvline(x=change_point_date, color='red', linestyle='-', linewidth=3, alpha=0.8)\n",
    "ax6.set_title('Key Events Timeline', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Date')\n",
    "ax6.set_ylabel('Event Category')\n",
    "ax6.set_yticks(range(5))\n",
    "ax6.set_yticklabels(['Geopolitical', 'Economic', 'OPEC Policy', 'Sanctions', 'Policy'])\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Brent Oil Change Point Analysis - Comprehensive Results', fontsize=20, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save key results for dashboard\n",
    "results_summary = {\n",
    "    'change_point_date': change_point_date.strftime('%Y-%m-%d'),\n",
    "    'change_point_index': tau_mean,\n",
    "    'mu_before': float(np.mean(mu_1_samples)),\n",
    "    'mu_after': float(np.mean(mu_2_samples)),\n",
    "    'sigma_before': float(np.mean(sigma_1_samples)),\n",
    "    'sigma_after': float(np.mean(sigma_2_samples)),\n",
    "    'annual_return_before': float(annual_mu_1),\n",
    "    'annual_return_after': float(annual_mu_2),\n",
    "    'annual_volatility_before': float(annual_sigma_1),\n",
    "    'annual_volatility_after': float(annual_sigma_2),\n",
    "    'prob_mu_increase': float(prob_mu_increase),\n",
    "    'prob_sigma_increase': float(prob_sigma_increase)\n",
    "}\n",
    "\n",
    "print(\"\\nAnalysis Summary for Dashboard:\")\n",
    "print(\"=\"*40)\n",
    "for key, value in results_summary.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Export data for dashboard\n",
    "oil_data.to_csv('../data/processed_oil_data.csv', index=False)\n",
    "events_data.to_csv('../data/processed_events_data.csv', index=False)\n",
    "\n",
    "# Save model results\n",
    "import json\n",
    "with open('../data/model_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(\"\\nData exported for dashboard creation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b62c3b4",
   "metadata": {},
   "source": [
    "## Conclusions and Business Recommendations\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Structural Break Detection**: The Bayesian change point analysis successfully identified a significant structural break in Brent oil price behavior, providing strong statistical evidence for regime shifts in the oil market.\n",
    "\n",
    "2. **Event Association**: The detected change point aligns temporally with major geopolitical and economic events in our dataset, suggesting causal relationships between these events and oil market dynamics.\n",
    "\n",
    "3. **Quantified Impact**: The analysis reveals measurable changes in both expected returns and volatility before and after the change point, with high statistical confidence.\n",
    "\n",
    "### Business Implications\n",
    "\n",
    "#### For Investors\n",
    "- **Risk Management**: The identified volatility regime changes provide crucial insights for portfolio risk assessment\n",
    "- **Strategic Positioning**: Understanding structural breaks helps optimize entry/exit timing for oil-related investments\n",
    "- **Hedging Strategies**: Volatility change patterns inform derivative strategies and hedging decisions\n",
    "\n",
    "#### for Policymakers\n",
    "- **Economic Stability**: Early detection of regime shifts can inform monetary and fiscal policy responses\n",
    "- **Energy Security**: Understanding event impacts helps develop robust energy security frameworks\n",
    "- **International Relations**: Geopolitical event analysis supports diplomatic and trade policy decisions\n",
    "\n",
    "#### For Energy Companies\n",
    "- **Operational Planning**: Structural break insights inform production scheduling and capacity planning\n",
    "- **Financial Planning**: Volatility regime identification supports budgeting and financial forecasting\n",
    "- **Supply Chain Management**: Event impact analysis helps optimize inventory and logistics strategies\n",
    "\n",
    "### Limitations and Considerations\n",
    "\n",
    "1. **Correlation vs. Causation**: While we identify temporal associations between events and change points, establishing definitive causation requires additional econometric analysis.\n",
    "\n",
    "2. **Model Assumptions**: The single change point model assumes one major structural break. Multiple change points may exist in the data.\n",
    "\n",
    "3. **Event Selection**: Our analysis focuses on 15 major events. Additional events may have influenced oil prices.\n",
    "\n",
    "4. **Forward-Looking Limitations**: Historical patterns may not perfectly predict future market behavior due to evolving market structures.\n",
    "\n",
    "### Future Work Recommendations\n",
    "\n",
    "1. **Multiple Change Points**: Implement models capable of detecting multiple change points for more granular analysis\n",
    "2. **Multivariate Analysis**: Incorporate additional economic indicators (GDP, inflation, exchange rates) for comprehensive modeling\n",
    "3. **Real-time Monitoring**: Develop systems for real-time change point detection to enable proactive decision-making\n",
    "4. **Sector-specific Analysis**: Extend analysis to other energy commodities and related sectors"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
